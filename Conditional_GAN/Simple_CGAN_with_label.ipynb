{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple_CGAN_with_label.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Machine-Learning-Tokyo/Intro-to-GANs/blob/master/Conditional_GAN/Simple_CGAN_with_label.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "BapB5eokALIt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Conditional GAN (CGAN)\n",
        "### (with prediction of the label)"
      ]
    },
    {
      "metadata": {
        "id": "3ZD7AhINAXoa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is a simple Conditional GAN based on the same template as [this](https://colab.research.google.com/drive/1RxJBQQJf7tszqFyKte8jsFtOF-oE89Y9) one. The difference is that in this case, we don't pass the label to the discriminator as an input, but instead we ask from the discriminator to find the most suitable label for the given image."
      ]
    },
    {
      "metadata": {
        "id": "KlRx5ymdZG0E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ]
    },
    {
      "metadata": {
        "id": "tHZUZmOUNEoJ",
        "colab_type": "code",
        "outputId": "a7427a75-73a7-4fc9-99ae-15e4a8d50710",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, BatchNormalization, Reshape, Flatten\n",
        "from keras.layers import Embedding, multiply, add, concatenate\n",
        "from keras.utils.np_utils import to_categorical #NEW!\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.datasets import mnist, fashion_mnist\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "uvvPV_WIZoR2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Function to build the generator"
      ]
    },
    {
      "metadata": {
        "id": "92JzJXoJBjWb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The generator is the same as in the previous case"
      ]
    },
    {
      "metadata": {
        "id": "6gqJ4ZrmNHve",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_generator(noise_size, img_shape, classes_num):\n",
        "  \n",
        "  noise = Input((noise_size,))\n",
        "  label = Input((1,), dtype='int32')\n",
        "  \n",
        "  embedded_label = Flatten()(Embedding(classes_num, noise_size)(label))\n",
        "  model_input = concatenate([noise, embedded_label])\n",
        "  \n",
        "  x = Dense(256)(model_input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(alpha=0.2)(x)\n",
        "  \n",
        "  x = Dense(512)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(alpha=0.2)(x)\n",
        "  \n",
        "  x = Dense(1024)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(alpha=0.2)(x)\n",
        "  \n",
        "  x = Dense(np.prod(img_shape), activation='tanh')(x)\n",
        "  img = Reshape(img_shape)(x)\n",
        "    \n",
        "  generator = Model([noise, label], img)\n",
        "  return generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ooEwRbP8eLgw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Function to build the discriminator"
      ]
    },
    {
      "metadata": {
        "id": "CLDFEGhXB1H5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this case the discriminator takes one input (the image) and returns two outputs:\n",
        "- The validity of the input image (same as previous)\n",
        "- The label of the image as a softmax tensor (similar to probabilities)"
      ]
    },
    {
      "metadata": {
        "id": "UysJTIlPOlZS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_discriminator(img_shape, classes_num):\n",
        "    \n",
        "  img = Input(img_shape)\n",
        "  f_img = Flatten()(img)\n",
        "  \n",
        "  x = Dense(1024)(f_img) #CHANGED!\n",
        "  x = LeakyReLU(alpha=0.2)(x)\n",
        "  \n",
        "  x = Dense(512)(x)\n",
        "  x = LeakyReLU(alpha=0.2)(x)\n",
        "  \n",
        "  x = Dense(256)(x)\n",
        "  x = LeakyReLU(alpha=0.2)(x)\n",
        "  \n",
        "  validity = Dense(1, activation='sigmoid')(x)\n",
        "  label = Dense(classes_num, activation='softmax')(x) #NEW!\n",
        "  \n",
        "  discriminator = Model(img, [validity, label]) #CHANGED!\n",
        "  return discriminator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uxDM6ldueOte",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Function to compile the models"
      ]
    },
    {
      "metadata": {
        "id": "gEfTuy93PRNb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_compiled_models(generator, discriminator, noise_size):\n",
        "  \n",
        "  optimizer = Adam(0.0002, 0.5)\n",
        "  \n",
        "  discriminator.compile(optimizer,\n",
        "                        loss=['binary_crossentropy', 'categorical_crossentropy'], #CHANGED!\n",
        "                        metrics=['accuracy'])\n",
        "  discriminator.trainable = False\n",
        "  \n",
        "  noise = Input((noise_size,))\n",
        "  label = Input((1,), dtype='int32')\n",
        "  img = generator([noise, label])\n",
        "  validity, d_label = discriminator(img) #CHANGED!\n",
        "  combined = Model([noise, label], [validity, d_label]) #CHANGED!\n",
        "  \n",
        "  combined.compile(optimizer, loss=['binary_crossentropy', 'categorical_crossentropy']) #CHANGED!\n",
        "  \n",
        "  return generator, discriminator, combined"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ocu71YfmeSIH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Function to sample and save generated images"
      ]
    },
    {
      "metadata": {
        "id": "X4-ejg8UTwqV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sample_imgs(generator, noise_size, step, classes_num, plot_img=True):\n",
        "  \n",
        "  r, c = classes_num, 5\n",
        "  imgs = []\n",
        "  for i in range(c):\n",
        "    noise = np.random.normal(0, 1, (r, noise_size))\n",
        "    sampled_labels = np.arange(r).reshape(-1, 1)\n",
        "    img = generator.predict([noise, sampled_labels])\n",
        "    img = img / 2 + 0.5\n",
        "    imgs.append(img)\n",
        "  \n",
        "  figsize = 1 * c, 1 * r\n",
        "  fig, axs = plt.subplots(r, c, figsize=figsize)\n",
        "  \n",
        "  for i in range(r):\n",
        "    for j in range(c):\n",
        "      axs[i, j].imshow(imgs[j][i], cmap='gray')\n",
        "      axs[i, j].axis('off')\n",
        "  plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
        "  fig.savefig(f'/content/images/{step}.png')\n",
        "  if plot_img:\n",
        "    plt.show()\n",
        "  plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K3ofIxpleVoc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Function to train the models"
      ]
    },
    {
      "metadata": {
        "id": "UH2BZtvTOEKP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The training follows the same pattern as in the previous case. This time, the discriminator has one input and two outputs, while the combined model two inputs and two outputs. Pay attetion to the fact that the input label is a single integer, while the target label is a [one-hot](https://keras.io/utils/#to_categorical) vector."
      ]
    },
    {
      "metadata": {
        "id": "wHI7xwGMQRAW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(models, noise_size, img_shape, batch_size, steps, classes_num):\n",
        "  \n",
        "  generator, discriminator, combined = models\n",
        "  #get real data\n",
        "  (X_train, Y_train), (X_val, Y_val) = fashion_mnist.load_data()\n",
        "  mnist_imgs = np.concatenate((X_train, X_val)) / 127.5 - 1 \n",
        "  mnist_labels = np.concatenate((Y_train, Y_val))\n",
        "  \n",
        "  for step in range(1, steps + 1):\n",
        "    # train discriminator\n",
        "    inds = np.random.randint(0, mnist_imgs.shape[0], batch_size)\n",
        "    real_imgs, labels = mnist_imgs[inds], mnist_labels[inds]\n",
        "    real_validity = np.ones(batch_size)\n",
        "    \n",
        "    noise = np.random.normal(0, 1, (batch_size, noise_size))\n",
        "    gen_imgs = generator.predict([noise, labels])\n",
        "    gen_validity = np.zeros(batch_size) \n",
        "\n",
        "    one_hot_labels = to_categorical(labels, num_classes=classes_num) #NEW!\n",
        "    r_loss = discriminator.train_on_batch(real_imgs, [real_validity, one_hot_labels]) #CHANGED!\n",
        "    g_loss = discriminator.train_on_batch(gen_imgs, [gen_validity, one_hot_labels]) #CHANGED!\n",
        "    disc_loss = np.add(r_loss, g_loss) / 2\n",
        "    \n",
        "    # train generator\n",
        "    noise = np.random.normal(0, 1, (batch_size, noise_size))\n",
        "    gen_validity = np.ones(batch_size)\n",
        "    gen_loss = combined.train_on_batch([noise, labels], [gen_validity, one_hot_labels]) #CHANGED!\n",
        "    \n",
        "    #print progress\n",
        "    if step % 100 == 0:\n",
        "      print('step: %d, D_loss: %f, D_accuracy: %d%%, '\n",
        "            'D_label_accuracy: %d%%, G_loss: %f' % (step, disc_loss[0],\n",
        "                                                    round(disc_loss[3] * 100), #CHANGED!\n",
        "                                                    round(disc_loss[4] * 100), #CHANGED!\n",
        "                                                    gen_loss[0]))\n",
        "    \n",
        "    # save_samples\n",
        "    if step % 100 == 0:\n",
        "      sample_imgs(generator, noise_size, step, classes_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jHnx_qUceZyc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define hyperparameters"
      ]
    },
    {
      "metadata": {
        "id": "1-ePrmDUVBYM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "noise_size = 100\n",
        "img_shape = 28, 28\n",
        "batch_size = 32\n",
        "steps = 5000\n",
        "classes_num = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lhkkM5ctecbb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Generate the models"
      ]
    },
    {
      "metadata": {
        "id": "FCr5cDHOZCdW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generator = build_generator(noise_size, img_shape, classes_num)\n",
        "discriminator = build_discriminator(img_shape, classes_num)\n",
        "compiled_models = get_compiled_models(generator, discriminator, noise_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zTkuRejSefba",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train the models"
      ]
    },
    {
      "metadata": {
        "id": "JznD-Lt6Y2h_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%rm -r /content/images\n",
        "%mkdir /content/images\n",
        "train(compiled_models, noise_size, img_shape, batch_size, steps, classes_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7BDEKYo9ehjq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Display samples"
      ]
    },
    {
      "metadata": {
        "id": "ia-xsFkmVxTc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Image('/content/images/%d.png' % 5000)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}